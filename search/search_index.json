{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83e\udde0 MEG/EEG GUI Software","text":"<p>Welcome to the documentation of DeepEpiX, a Dash-based MEG/EEG GUI Software. This app provides an interactive web interface for loading, preprocessing, annotating and analyzing raw MEG/EEG files, and last but not least: running prediction models.</p> <p></p>"},{"location":"#what-this-app-does","title":"\ud83d\ude80 What This App Does","text":"<ul> <li>\u2705 Load raw MEG/EEG datasets (<code>.ds</code>, <code>.fif</code>, or 4D-compatible)</li> <li>\u2705 Set frequency filtering parameters (resampling, high-pass, low-pass, notch)</li> <li>\u2705 Detect ECG peaks via channel hinting</li> <li>\u2705 Drop bad channels</li> <li>\u2705 Visualize event statistics, power spectral density, topomap, ICA...</li> <li>\u2705 Display temporal signal with various options</li> <li>\u2705 Create custom sensors layout (montage)</li> <li>\u2705 Run prediction models</li> <li>\u2705 Measure their performances</li> </ul>"},{"location":"#what-this-app-should-do-in-the-future","title":"\ud83e\udd14 What This App Should Do in the Future","text":"<ul> <li>\ud83d\udca1 Allow continuous learning of prediction models</li> </ul>"},{"location":"#app-structure","title":"\ud83d\uddc2 App Structure","text":"<p>The app is structured around pages, layout and callbacks.</p>"},{"location":"#docs-navigation","title":"\ud83d\udcd6 Docs Navigation","text":"<ul> <li>\ud83d\udce6 Folder Structure</li> <li>\ud83e\udde9 Page: Preprocessing</li> <li>\ud83d\udcca Page: PSD</li> <li>\ud83d\udd04 Callback Glossary</li> <li>\ud83d\udc68\u200d\ud83d\udcbb Developer Setup</li> </ul>"},{"location":"#who-is-this-for","title":"\ud83d\udc69\u200d\ud83d\udcbb Who Is This For?","text":"<ul> <li>Developers extending or maintaining the app</li> <li>Researchers and clinicians using the app for MEG/EEG studies</li> <li>Contributors improving UI, performance, or adding features</li> </ul>"},{"location":"app-structure/","title":"\ud83d\udcc2 The Dropdown Menu Explained","text":"<p>The application is divided into four main sections, each with its own set of pages.</p> <p></p>"},{"location":"folder-structure/","title":"\ud83d\uddc3\ufe0f Folder Structure","text":"<pre><code>DeepEpiX/\n\n\u251c\u2500\u2500 data/                 # Put your data here - when built with Docker, local data directory is mounted on it.\n\u2502   \u251c\u2500\u2500 patient_1.ds      \n\u2502   \u251c\u2500\u2500 patient_2.fif\n\u2502   \u251c\u2500\u2500 patient_3_4D/\n\u2502   \u2502   \u251c\u2500\u2500 rfDC_EEG\n\u2502   \u2502   \u251c\u2500\u2500 config\n\u2502   \u2502   \u2514\u2500\u2500 hs_file\n\n\u251c\u2500\u2500 docs/                 # Use mkdocs\n\n\u251c\u2500\u2500 requirements/         # Use pip-tools to generate .txt from .in\n\n\u251c\u2500\u2500 src/                  \n\u2502   \u251c\u2500\u2500 assets/           # Static image/logo/icons\n\u2502   \u251c\u2500\u2500 cache-directory/  # Cached intermediate data or results - cleaned every time a new subect is loaded\n\n\u2502   \u251c\u2500\u2500 callbacks/        # Contains chainable functions that are automatically called whenever a UI element on viz.py page is changed\n\u2502   \u2502   \u251c\u2500\u2500 utils/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 page1_utils.py \n\u2502   \u2502   \u2502   \u251c\u2500\u2500 page2_utils.py \n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 pageN_utils.py\n\u2502   \u2502   \u251c\u2500\u2500 page1_layout.py \n\u2502   \u2502   \u251c\u2500\u2500 page2_layout.py \n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u2514\u2500\u2500 page3_layout.py  \n\n\u2502   \u251c\u2500\u2500 layout/           # Contains UI elements definition\n\u2502   \u2502   \u251c\u2500\u2500 page1_callbacks.py \n\u2502   \u2502   \u251c\u2500\u2500 page2_callbacks.py \n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u2514\u2500\u2500 pageN_callbacks.py  \n\n\u2502   \u251c\u2500\u2500 model_pipeline/   # Extracted from https://github.com/pmouches/DeepEpi/tree/main/pipeline with some modifications\n\u2502   \u251c\u2500\u2500 models/           # ML models from from https://github.com/pmouches/DeepEpi/tree/main/\n\n\u2502   \u251c\u2500\u2500 pages/            # Multi-page app\n\u2502   \u2502   \u251c\u2500\u2500 page1.py \n\u2502   \u2502   \u251c\u2500\u2500 page2.py \n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u2514\u2500\u2500 pageN.py\n\n\u2502   \u251c\u2500\u2500 static/           # Static files\n\u2502   \u251c\u2500\u2500 config.py         # Configuration settings and constants\n\u2502   \u2514\u2500\u2500 run.py            # Entry point to run the multi-page app\n\n\n\u251c\u2500\u2500 DeepEpiX.def          # Singularity definition file for containerization\n\u251c\u2500\u2500 Dockerfile            # Docker definition file for containerization\n\u2514\u2500\u2500 README.md \n</code></pre> <p>This structure is schematic but aims to help you understand how the multi-page Dash app is organized.</p> <p>Each page is defined in the <code>pages/</code> directory:</p> <ul> <li>The layout of each page is declared in <code>layout/</code>.</li> <li>The interactivity (callbacks) is handled in <code>callbacks/</code>.</li> </ul> <p>\ud83d\udd0e Note: Since several pages share common callback functions, the callbacks, layout components, and utilities are organized by major components (e.g., <code>graph</code>, <code>history</code>, <code>ica</code>, <code>prediction</code>, <code>preprocessing</code>, etc.), rather than strictly by individual pages.</p>"},{"location":"install/","title":"\ud83d\udc0b Quick Start : Docker Installation (for Production Mode only)","text":"<p>Clone the Repository in your working directory: <pre><code>git clone https://github.com/agnesgrd/DeepEpiX.git\n</code></pre></p> <p>Build and Run the Docker Container with your Local Data Directory: <pre><code>cd DeepEpiX\ndocker build -t deepepix-app .\ndocker run -p 8050:8050 -v /home/user/DeepEpiX/data:/DeepEpiX/data deepepix-app # Modify this to point your local data path\n</code></pre></p> <p>Example of Windows Path to Point to your Data Directory: <pre><code>docker run -p 8050:8050 -v //c/Users/pauli/Documents/MEGBase/data/exampleData:/DeepEpiX/data deepepix-app\n</code></pre></p> <p>Then, open the app in your web browser at: http://localhost:8050/</p> <p>You are Ready to Use DeepEpiX ! \ud83e\udd38\u200d\u2642\ufe0f</p>"},{"location":"install/#local-installation-for-development-mode","title":"\ud83d\udee0 Local Installation (for Development Mode)","text":"<p>\u21aa\ufe0f Go to Developer Guide &gt; Setup &amp; Run</p>"},{"location":"dev/new_page/","title":"\ud83d\udcc4 Adding a New Page","text":"<p>If you want to add a completely new feature to the app \u2014 for example, continuous learning of models \u2014 the easiest and cleanest way is to create a new, self-contained page.</p> <p>Since pages in this app do not directly communicate with one another (except through <code>dcc.Store</code> components), isolating your feature into its own page helps avoid unnecessary complexity or deep code digging.</p>"},{"location":"dev/new_page/#5-steps-to-add-a-new-feature-page","title":"\u2795 5 Steps to Add a New Feature Page","text":"<ol> <li> <p>Create the page file.    Add a new file named <code>new_page.py</code> in the <code>pages/</code> directory.</p> </li> <li> <p>Register the page.    Inside the new file, include the following line:    <pre><code>dash.register_page(__name__, name = \"New page\", path=\"/path/to/the/new/page\")\n</code></pre></p> </li> <li> <p>Define the layout.    Create a variable or function named layout that returns the page\u2019s content:    <pre><code>layout = html.Div([  \n   #Your page components here \n])\n</code></pre></p> </li> <li> <p>Define the callbacks.     Write callback functions that dynamically update your page components.     Use the following pattern to register callbacks:     Call this registration function inside <code>new_page.py</code>. <pre><code># callbacks/your_feature.py\ndef register_new_callbacks(**your_args):\n   @callback(\n      Output(component1, 'property1'),\n      Output(component2, 'property2'),\n      Input(component3, 'property3'),\n      State(component4, 'property4')\n   )\n   def _new_callbacks(input_value, state_value):\n      # Your logic here\n      return updated_value1, updated_value2\n</code></pre></p> </li> <li> <p>Update run.py (main app file).    The app is already initialized with multi-page support:    <pre><code>app = Dash(__name__, use_pages=True)\n</code></pre>    Ensure the new page is included using dash.page_container.    You can also control the page's order or placement in the DropdownMenu component from here.</p> </li> </ol> <p>\ud83d\udca1 Best Practice: Group related callbacks into separate files inside the <code>callbacks/</code> directory. Structure them by feature or component (e.g., <code>graph.py</code>, <code>prediction.py</code>), not strictly by page.</p>"},{"location":"dev/new_page/#resources","title":"\ud83d\udcda Resources","text":"<p>To better understand how multi-page apps work in Dash, see the official documentation:</p> <p>\ud83d\udd17 https://dash.plotly.com/urls</p>"},{"location":"dev/setup/","title":"Setup & run","text":""},{"location":"dev/setup/#local-installation-for-development-mode","title":"\ud83d\udee0 Local Installation (for Development Mode)","text":"<ol> <li> <p>Clone the Repository in your working directory: <pre><code>git clone https://github.com/agnesgrd/DeepEpiX.git\n</code></pre></p> </li> <li> <p>Set up the Dash Environment: <pre><code>cd DeepEpiX\npython3 -m venv .dashenv\nsource .dashenv/bin/activate\npython3 -m pip install -r requirements/requirements-python3.9.txt\ndeactivate\n</code></pre></p> </li> <li> <p>Set up Prediction Model Environments: <pre><code>python3 -m venv .tfenv\nsource .tfenv/bin/activate\npython3 -m pip install -r requirements/requirements-tfenv.txt\ndeactivate\n</code></pre> <pre><code>python3 -m venv .torchenv\nsource .torchenv/bin/activate\npython3 -m pip install -r requirements/requirements-torchenv.txt\ndeactivate\n</code></pre></p> </li> <li>Activate your Dash Environment and Start Running the App: <pre><code>source .dashenv/bin/activate\npython3 src/run.py\n</code></pre> Then, open the app in your web browser at: http://localhost:8050/</li> </ol> <p>\ud83e\udd73 You can start editing code while visualizing automatic reloads (if DEBUG is set to True in <code>config.py</code>). </p> <p>For quick access, ensure that your MEG data is placed in the data folder within the project directory.</p>"},{"location":"dev/setup/#development-notes","title":"\ud83d\uddd2\ufe0f Development Notes","text":"<ul> <li> <p>\ud83d\udc0d Python Version:   DeepEpiX was developed using Python 3.9. It is recommended to use this version to ensure compatibility.</p> </li> <li> <p>\ud83e\uddf0 Recommended Developer Tools:</p> <ul> <li> <p><code>pip-tools</code>:     Helps manage and compile <code>requirements.in</code> into a clean, version-pinned <code>requirements.txt</code>.     <pre><code>pip install pip-tools\npip-compile --output-file=requirements.txt requirements.in\n</code></pre></p> </li> <li> <p><code>mkdocs</code>:     Used to build clean, static documentation sites from Markdown files.     <pre><code>pip install mkdocs\nmkdocs serve  # Preview the docs locally\nmkdocs build  # Generate the static site\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"dev/subprocess/","title":"\u2699\ufe0f Running External Scripts with <code>subprocess</code> in Python","text":"<p>This section describes how to run a Python script in a separate virtual environment using the <code>subprocess</code> module. This approach is useful when models or pipelines require isolated environments like TensorFlow or PyTorch.</p>"},{"location":"dev/subprocess/#use-case-executing-a-model-in-a-separate-virtual-environment","title":"\ud83d\udcc1 Use Case: Executing a Model in a Separate Virtual Environment","text":"<p>To simplify development and reduce dependency conflicts, we separated the Dash environment from heavy ML frameworks like TensorFlow and PyTorch:</p> <ul> <li> <p>The Dash app runs inside a lightweight environment:  </p> <ul> <li><code>.dashenv</code></li> </ul> </li> <li> <p>The model listed in <code>models/</code> require dedicated ML environments:</p> <ul> <li><code>.tfenv</code></li> <li><code>.torchenv</code></li> </ul> </li> </ul> <p>When the user decides to run a model, the app should detect the required backend and delegate execution to the appropriate Python binary.</p> <p>Below is an example script we want to run using a specific ML environment (<code>model_pipeline/run_model.py</code>).</p> <pre><code># model_pipeline/run.model.py\nfrom ... import run_model_pipeline\n\nif __name__ == \"__main__\":\n    model_path = sys.argv[1]\n    model_type = sys.argv[2]\n    subject_folder_path = sys.argv[3]\n    results_path = sys.argv[4]\n    threshold = float(sys.argv[5])\n    adjust_onset = sys.argv[6]\n    bad_channels = sys.argv[7]\n\n    run_model_pipeline(model_path, model_type, subject_folder_path, results_path, threshold, adjust_onset, bad_channels)\n</code></pre>"},{"location":"dev/subprocess/#step-by-step-example","title":"\u2705 Step-by-Step Example","text":"<ol> <li>Classical Import <pre><code># callbacks/predict_callbacks.py\nimport subprocess\nimport os\nimport time\nfrom pathlib import Path\n</code></pre></li> <li> <p>Backend Detection</p> <p><pre><code>    # Select the Python executable based on the virtual environment\n    if \"TensorFlow\" in venv:\n        ACTIVATE_ENV = f\"../{config.TENSORFLOW_ENV}/bin/python\"\n    elif \"PyTorch\" in venv:\n        ACTIVATE_ENV = f\"../{config.TORCH_ENV}/bin/python\"\n</code></pre> The variable <code>venv</code> is determined earlier in the function based on the model file's extension (<code>.pth</code>, .<code>keras</code>, <code>h5</code>).</p> </li> <li> <p>Command Definition</p> <p>The command should be passed as a list of strings, where each list element is a separate argument. <pre><code>    # Build the command to execute\n    command = [\n        ACTIVATE_ENV,\n        \"model_pipeline/run_model.py\",         # Script to run\n        str(model_path),                       # Argument 1\n        str(venv),                             # Argument 2\n        str(subject_folder_path),              # Argument 3\n        str(cache_dir),                        # Argument 4\n        str(threshold),                        # Argument 5\n        str(adjust_onset),                     # Argument 6\n        str(channel_store.get('bad', []))      # Argument 7\n    ]\n</code></pre></p> </li> <li> <p>Python Path</p> <p>If the <code>PYTHONPATH</code> environment variable isn't set correctly when using <code>subprocess</code>, Python may not be able to locate local modules properly, leading to import failures.</p> <pre><code>    # Set the working directory and environment variables\n    working_dir = Path.cwd()\n    env = os.environ.copy()\n    env[\"PYTHONPATH\"] = str(working_dir)  # Ensure imports work correctly\n</code></pre> </li> <li> <p>Subprocess execution <pre><code>    # Run the subprocess\n    try:\n        subprocess.run(command, env=env, text=True)  # Run command in isolated process\n\n    except Exception as e:\n        print(f\"\u26a0\ufe0f Error running model: {e}\")\n</code></pre>     Use <code>text=True</code> to ensure output is treated as text (not bytes).     To suppress output, uncomment <code>stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL</code>.</p> </li> </ol>"},{"location":"dev/subprocess/#tips","title":"\ud83d\udca1 Tips","text":"<ul> <li> <p>To retrieve model results afterward, make sure your script saves outputs (e.g., CSVs, logs) into the <code>cache-directory</code>/.</p> </li> <li> <p>Async option: use <code>multiprocessing</code> or <code>ThreadPoolExecutor</code> if you don\u2019t want the Dash app to freeze during long model runs.</p> </li> </ul>"},{"location":"dev/subprocess/#when-to-use-this","title":"\ud83d\udcd8 When to Use This","text":"<p>Use a subprocess when:</p> <ul> <li> <p>You want to isolate dependencies (e.g., TensorFlow vs. PyTorch).</p> </li> <li> <p>You need to run long or blocking processes separately.</p> </li> </ul>"},{"location":"user/dataset/","title":"\ud83d\udcd8 Tuto 1 : Load &amp; Preprocess Data","text":""},{"location":"user/dataset/#1-go-to-home-page","title":"1\ufe0f\u20e3 Go to Home Page","text":"<p>Open the app as explained in the Setup &amp; Installation section. You should arrive at the \ud83c\udfe0 Home Page. If not, use the \u2630 menu at the top left to navigate there.</p>"},{"location":"user/dataset/#2-choose-a-subject","title":"2\ufe0f\u20e3 Choose a Subject","text":"<p>Use the \ud83d\udd3d dropdown menu to select a subject. \ud83d\udc49 Note: The \ud83d\udcc2 Open Folder button only works if you have installed DeepEpiX locally.</p> <p>You can open the following types of files:</p> <ul> <li>\ud83d\udcc1 <code>.ds</code> folders</li> <li>\ud83d\udcc4 <code>.fif</code> files</li> <li>\ud83e\udde0 <code>4D</code> folders (must include at least: <code>rfDC-EEG</code>, <code>config</code> and <code>hs-file</code>)</li> </ul>"},{"location":"user/dataset/#3-load-and-access-metadata","title":"3\ufe0f\u20e3 Load and Access Metadata","text":"<p>When you click on \ud83d\udce5 Load, the previous database memory will be cleared \ud83e\uddf9.</p> <p>After loading, \u2699\ufe0f preprocessing parameters become accessible. You can adjust these settings while exploring:</p> <ul> <li>\ud83d\udcca Metadata (<code>raw.info</code>)</li> <li>\ud83d\uddc2\ufe0f Past annotations</li> <li>\ud83d\udcc9 Power spectrum decomposition (as a function of frequency parameters)</li> </ul>"},{"location":"user/dataset/#4-preprocess-and-visualize","title":"4\ufe0f\u20e3 Preprocess and Visualize","text":"<p>Clicking \u26a1 Preprocess will:</p> <ul> <li>\ud83e\uddf9 Filter and resample the data</li> <li>\ud83d\udcbe Store it in memory</li> </ul> <p>This will take you to the \ud83d\udcc8 Raw Visualization main page.</p> <p>To view metadata again, return to the \ud83c\udfe0 Home Page and check the \ud83d\udcda Database table.</p>"},{"location":"user/montage/","title":"\ud83d\udcd8 Tuto 2: Create New Sensors Layout (Montage)","text":"<p>What is a montage? For clinicians, creating custom sensor montages is essential for efficient analysis. Rather than viewing all available channels, a montage allows you to focus on specific brain regions of interest, making it easier to identify and analyze neural activity patterns relevant to your clinical assessment.</p>"},{"location":"user/montage/#1-choose-a-name","title":"1\ufe0f\u20e3 Choose a Name","text":"<p>Click on the \u2795 Create button to begin.</p>"},{"location":"user/montage/#2-choose-a-selection-method","title":"2\ufe0f\u20e3 Choose a Selection Method","text":"<p>You have two options:</p>"},{"location":"user/montage/#choose-sensors-manually","title":"\ud83d\uddb1\ufe0f Choose Sensors Manually","text":"<p>Select the sensors you want one by one.</p>"},{"location":"user/montage/#choose-with-random-pick","title":"\ud83c\udfb2 Choose with Random Pick","text":"<ul> <li>Apply a % percentage on all groups</li> <li>and/or adjust counts directly for each group</li> </ul> <p>\ud83d\udcda Note about groups: Sensor groups are defined based on anatomical brain regions as described in [paper references to be added].</p> <p>You can see the results live on the left side.</p>"},{"location":"user/montage/#3-save-and-locate","title":"3\ufe0f\u20e3 Save and Locate","text":"<p>After you're satisfied, \ud83d\udcbe save your montage locally.</p> <p>You can now find it:</p> <ul> <li>In the \ud83d\uddc2\ufe0f Montage Table</li> <li>Or under \ud83e\udde0 Select Montage in the visualization pages</li> </ul> <p>\u26a0\ufe0f Note: A montage is specific to the channel name format (e.g., <code>MRC22-2805</code> \u2260 <code>A22</code>) and to the available channels of the patient loaded at the time of creation. This explains why a selected montage may not work properly during visualization, even when the channel formats appear similar.</p>"},{"location":"user/montage/#4-manage-your-montage","title":"4\ufe0f\u20e3 Manage Your Montage","text":"<p>You can easily delete a montage by clicking on the \ud83d\uddd1\ufe0f trash icon next to it.</p>"}]}